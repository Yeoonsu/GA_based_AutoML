{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BPIC2012\n",
    "caseid = 'Case ID'\n",
    "activity = 'Activity'\n",
    "ts = 'Complete Timestamp'\n",
    "label = {'Activity' : 'O_ACCEPTED-COMPLETE'}\n",
    "other_features = ['Resource', 'Variant index', '(case) AMOUNT_REQ']\n",
    "\n",
    "## BPIC2017\n",
    "# caseid = 'Case ID'\n",
    "# activity = 'Activity'\n",
    "# ts = 'Complete Timestamp'\n",
    "# label = {'column' : 'Accepted'}\n",
    "# other_features = ['Resource', 'CreditScore', 'FirstWithdrawalAmount', 'MonthlyCost', 'NumberOfTerms','OfferedAmount']\n",
    "\n",
    "## BPIC2015\n",
    "# caseid = 'Case ID'\n",
    "# activity = 'Activity'\n",
    "# ts = 'Complete Timestamp'\n",
    "# label = {'column' : 'Label'}\n",
    "# other_features = ['Resource', 'monitoringResource', '(case) Includes_subCases','(case) Responsible_actor','(case) caseProcedure','(case) caseStatus','(case) last_phase','(case) parts',\n",
    "#                 '(case) requestComplete','(case) termName', '(case) SUMleges']\n",
    "\n",
    "combi = ['bucketing', 'encoding', 'drop_act', 'params']\n",
    "\n",
    "options = {\n",
    "    'bucketing' : (1,40), # a number of partitions\n",
    "    \n",
    "    'encoding' : ['index', 'aggregate'],\n",
    "    \n",
    "    'drop_act' : [2,4,6,8], # a number of activities to drop\n",
    "    \n",
    "    'models' : ['Decision Tree','Random Forest','LightGBM','Xgboost'],\n",
    "\n",
    "    'params' : {'Decision Tree':{'max_depth': (2,20),\n",
    "                           'min_samples_leaf': (5,100),\n",
    "                           'criterion': [\"gini\", \"entropy\"]\n",
    "            }, \n",
    "            'Random Forest':{\"n_estimators\": (10,1000), \n",
    "                           \"max_depth\": (2,20),\n",
    "                           \"max_features\": [\"auto\", \"log2\"], \n",
    "                           \"bootstrap\": [True, False],\n",
    "                           \"criterion\": [\"gini\", \"entropy\"]\n",
    "            },\n",
    "            'LightGBM':{'max_depth': (2,20),\n",
    "                      'num_leaves' : (10,500),\n",
    "                      'min_child_samples' : (2,10)\n",
    "            },\n",
    "            'Xgboost':{\"max_depth\": (2,20),\n",
    "                     \"n_estimators\": (10,1000),\n",
    "                     \"learning_rate\": [0.01, 0.05, 0.1]\n",
    "                     \n",
    "            }\n",
    "            }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "def add_label(df):       \n",
    "    Label = []\n",
    "    if 'Activity' in label:\n",
    "        label_col = label['Activity']                \n",
    "        for case, group in df.groupby(caseid):\n",
    "            for i in range(len(group)):\n",
    "                if label_col in group[activity].tolist():\n",
    "                    Label.append(1)\n",
    "                else:\n",
    "                    Label.append(0)\n",
    "        label_df = pd.DataFrame(Label, columns = ['Label'])\n",
    "        df = pd.concat([df, label_df], axis=1)\n",
    "\n",
    "    elif 'column' in label:\n",
    "        label_col = label['column']\n",
    "        df = df.rename(columns={label_col : 'Label'})\n",
    "    return df\n",
    "\n",
    "def drop_activity(df, n):\n",
    "    trace_num = df['Case ID'].nunique()\n",
    "    act = df['Activity'].value_counts()\n",
    "    df = df.iloc[[i for i in range(len(df)) if df.iloc[i]['Activity'] not in act[-n:]]]\n",
    "    return df\n",
    "\n",
    "def whole_bucket(df):\n",
    "    result = []\n",
    "    \n",
    "    for prefix in tqdm(range(2,42)):\n",
    "        bucket=[]\n",
    "        for case, group in df.groupby(caseid):\n",
    "            group = group.sort_values(by=ts, ascending = True).reset_index(drop=True)\n",
    "            if len(group) >= prefix:\n",
    "                bucket.append(group.iloc[:prefix,:])\n",
    "        new_df = pd.concat(bucket)\n",
    "        result.append(new_df)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def prefix_bound(m, drop_low=False):\n",
    "    if m == 1:\n",
    "        if drop_low == True:\n",
    "            return [[4,40]]\n",
    "        else:\n",
    "            return [[2,40]]\n",
    "    \n",
    "    if drop_low == True:\n",
    "        if m > 37:\n",
    "            m = 37\n",
    "        prefix_len = 37//m\n",
    "        remain = 37%m\n",
    "        prev = 4\n",
    "        bound=[]\n",
    "        for i in range(m):\n",
    "            if i < remain:\n",
    "                bound.append([prev,prev+prefix_len+1])\n",
    "                prev = prev+prefix_len+1\n",
    "            else:\n",
    "                bound.append([prev,prev+prefix_len])\n",
    "                prev = prev+prefix_len\n",
    "    else:  \n",
    "        prefix_len = 39//m\n",
    "        remain = 39%m\n",
    "        prev = 2\n",
    "        bound=[]\n",
    "        for i in range(m):\n",
    "            if i < remain:\n",
    "                bound.append([prev,prev+prefix_len+1])\n",
    "                prev = prev+prefix_len+1\n",
    "            else:\n",
    "                bound.append([prev,prev+prefix_len])\n",
    "                prev = prev+prefix_len\n",
    "        \n",
    "    return bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GA : Genetic Algorithm\n",
    "RS : Random Search\n",
    "\"\"\"\n",
    "df = pd.read_csv('/Users/nahyun/Desktop/Project/rule-based-predictive-monitoring-master/data/dataset/bpic/BPIC12.csv')\n",
    "df = add_label(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = drop_activity(df, 2)\n",
    "df2 = drop_activity(df, 4)\n",
    "df3 = drop_activity(df, 6)\n",
    "df4 = drop_activity(df, 8)\n",
    "\n",
    "df_list1 = whole_bucket(df1)\n",
    "df_list2 = whole_bucket(df2)\n",
    "df_list3 = whole_bucket(df3)\n",
    "df_list4 = whole_bucket(df4)\n",
    "\n",
    "with open('df_list1.pkl', 'wb') as f1:\n",
    "    pickle.dump(df_list1, f1)\n",
    "    \n",
    "with open('df_list2.pkl', 'wb') as f2:\n",
    "    pickle.dump(df_list2, f2)\n",
    "    \n",
    "with open('df_list3.pkl', 'wb') as f3:\n",
    "    pickle.dump(df_list3, f3)\n",
    "    \n",
    "with open('df_list4.pkl', 'wb') as f4:\n",
    "    pickle.dump(df_list4, f4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
